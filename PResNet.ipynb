{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get relevant modules\n",
    "\n",
    "import torch \n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get working dataset and format it accordingly\n",
    "\n",
    "#MNIST\n",
    "transform = transforms.ToTensor()\n",
    "dataset = datasets.MNIST(root=\"data\", download=True, train=True, transform=transform)\n",
    "\n",
    "#define train and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "#split the dataset\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "\n",
    "class Layer(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, num_features):\n",
    "    super().__init__()\n",
    "\n",
    "    self.output = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "                kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm2d(num_features=num_features)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.output(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, num_features):\n",
    "    super().__init__()\n",
    "\n",
    "    self.layer_1 = Layer(in_channels, out_channels, kernel_size, stride, padding, num_features)\n",
    "    self.layer_2 = Layer(in_channels, out_channels, kernel_size, stride, padding, num_features)\n",
    "\n",
    "  def forward(self, x):\n",
    "            \n",
    "      #layer 1\n",
    "      x = self.layer_1(x)\n",
    "\n",
    "      #layer 2\n",
    "      x = self.layer_2(x)\n",
    "      \n",
    "      return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, num_features):\n",
    "    super().__init__()\n",
    "\n",
    "    self.initial_layer = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "          nn.ReLU(),\n",
    "          nn.BatchNorm2d(num_features=64),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    \n",
    "    self.block_1 = Block(in_channels, out_channels, kernel_size, stride, padding, num_features)\n",
    "    self.block_2 = Block(in_channels, out_channels, kernel_size, stride, padding, num_features)\n",
    "    self.block_3 = Block(in_channels, out_channels, kernel_size, stride, padding, num_features)\n",
    "\n",
    "    self.output = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(64*7*7, 10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    #initial conv layer + pooling\n",
    "    x = self.initial_layer(x)\n",
    "\n",
    "    #blocks\n",
    "    y = x\n",
    "    x = self.block_1(x)\n",
    "    x = torch.add(x, y) #skip connection: F(x) + x\n",
    "\n",
    "    y = x\n",
    "    x = self.block_2(x)\n",
    "    x = torch.add(x, y)\n",
    "\n",
    "    y = x\n",
    "    x = self.block_3(x)\n",
    "    x = torch.add(x, y)\n",
    "\n",
    "    #flatten then apply linear layer\n",
    "    x = self.output(y)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.015224847942590714\n",
      "Epoch 1: loss = 0.04075232893228531\n",
      "Epoch 2: loss = 0.00402669096365571\n",
      "Epoch 3: loss = 0.003790066111832857\n",
      "Epoch 4: loss = 0.007529288996011019\n",
      "Epoch 5: loss = 0.031100675463676453\n",
      "Epoch 6: loss = 0.0010145916603505611\n",
      "Epoch 7: loss = 0.0032656118273735046\n",
      "Epoch 8: loss = 5.103349849377992e-06\n",
      "Epoch 9: loss = 0.0072031812742352486\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "\n",
    "model = ResNet(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, num_features=64)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "model.train()\n",
    "\n",
    "best_loss = 1\n",
    "all_losses = []\n",
    "for epoch in range(10):\n",
    "  for inputs, targets in train_loader:\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    all_losses.append(loss.item())\n",
    "\n",
    "    if loss < best_loss:\n",
    "       best_model = deepcopy(model)\n",
    "       best_loss = loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  print(f\"Epoch {epoch}: loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.72%\n"
     ]
    }
   ],
   "source": [
    "#test the last model\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.76%\n"
     ]
    }
   ],
   "source": [
    "#test the model with the lowest loss during training\n",
    "\n",
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = best_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
